# use this properties file to generate the test collection index
# the topics learnt during the estimation phase over the training collection
# is used to generate the topical weights in the test index.

#coll=/mnt/sdb2/research/linkprediction/data/questions/train/
# the test set
#coll=/mnt/sdb2/research/linkprediction/data/questions/test/

index=/mnt/sdb2/research/linkprediction/data/index/train/

stem=true
stopfile=/mnt/sdb2/research/linkprediction/common_words

linkmap=/mnt/sdb2/research/linkprediction/data/links/postlinks.csv
tagsynmap=/mnt/sdb2/research/linkprediction/data/links/tagsyn.tsv
toptags=/mnt/sdb2/research/linkprediction/data/links/toptags.tsv

# can play around with these trying out various combinations
model.fields=title,body

# the tsv document to be read during inferencing is the test document
# in another properties file, we need to suppy the value of the training
# document...
doctext.file=/mnt/sdb2/research/linkprediction/data/tsv/small/test.tsv

# you can specify a label.topic map file here
#label.topic.map=

plda.perlabel.topics=2
plda.beta=0.01
plda.alpha=0.1

#number of iterations... small value set during testing purpose
plda.niters=50

lda.index=/mnt/sdb2/research/linkprediction/index/plda_tb/
lda.txt=/mnt/sdb2/research/linkprediction/data/models/lda/lda.txt
slda.index=/mnt/sdb2/research/linkprediction/index/slda/
slda.txt=/mnt/sdb2/research/linkprediction/data/models/slda/slda.txt

#z(d,n) for every word w in every document d
plda.saveto=/mnt/sdb2/research/linkprediction/data/models/plda/model.inf.plda
plda.topwords=/mnt/sdb2/research/linkprediction/data/models/plda/model.inf.twords
#plda.loadfrom=/mnt/sdb2/research/linkprediction/data/models/plda/model.plda
plda.index=/mnt/sdb2/research/linkprediction/index/plda/
plda.txt=/mnt/sdb2/research/linkprediction/data/models/plda/plda.txt

splda.saveto=/mnt/sdb2/research/linkprediction/data/models/splda/model.inf.splda
splda.topwords=/mnt/sdb2/research/linkprediction/data/models/splda/model.inf.twords
#splda.loadfrom=/mnt/sdb2/research/linkprediction/data/models/splda/model.splda
splda.index=/mnt/sdb2/research/linkprediction/index/splda/

pldp.inittopics=true
pldp.saveto=/mnt/sdb2/research/linkprediction/data/models/pldp/model.pldp
pldp.topwords=/mnt/sdb2/research/linkprediction/data/models/pldp/model.twords
#pldp.loadfrom=/mnt/sdb2/research/linkprediction/data/models/pldp/model.pldp

plda.out.ntopwords=5
plda.showprogress=200

# perform the m-step after this many sampling steps
splda.mstep=20
slda.infer.predictions=/mnt/sdb2/research/linkprediction/data/models/splda/testdocs.pred.out

retrieve.use_tags=true
retrieve.runname=splda

trace.level=0
retrieve.topicmodel=splda
retrieve.use_topics=false
retrieve.tags_only=true
retrieve.num_wanted=1000
retrieve.results_file=/mnt/sdb2/research/linkprediction/data/results/tags/tags.res

# this file is used for term selection function...
query.tsv.file=/mnt/sdb2/research/linkprediction/data/qrels/queries.txt
#query.wtsv.file=/mnt/sdb2/research/linkprediction/data/queries/splda.txt
query.tm_lambda=0.8
query.lambda=0.1
query.nterms=40

stripped_tag_tsv=/mnt/sdb2/research/linkprediction/data/queries/plda.notag.txt

retrieve.tm_lambda=0.2
retrieve.lambda=0.4
